\documentclass[12pt]{report} %fuente a 12pt

% MÁRGENES: 2,5 cm sup. e inf.; 3 cm izdo. y dcho.
\usepackage[
a4paper,
vmargin=2.5cm,
hmargin=3cm
]{geometry}

% ENLACES
\usepackage{hyperref}
\hypersetup{colorlinks=true,
	linkcolor=black, % enlaces a partes del documento (p.e. índice) en color negro
    urlcolor=blue} % enlaces a recursos fuera del documento en azul
    
\usepackage[spanish, es-tabla]{babel}
\usepackage{graphicx}
\usepackage{float}

% REVISAR FUENTES
% REVISAR FOTOS
% REVISAR NEGRITAS
% REVISAR CURSIVA

\title{Lyncex: describiendo una aplicación web como conocimiento}
\author{Adrián Arroyo Calle}
\date{Curso 2019-2020}

\begin{document}

\maketitle

\chapter{Introducción}

Lyncex es una base de datos y a la vez un servidor web configurable a través del contenido semántico de la propia base de datos.

\section{Introducción}
En ciencias de la computación, de forma recurrente se divide entre código, lo que va a ejecutar la máquina, y datos.
Esta diferencia, aunque pueda resultar evidente, es innecesaria, ya que el código no deja de ser dato, solo que con una semántica diferente.
Von Neuman, en su modelo de computadora, elimina las diferencias a nivel de hardware entre código y datos, de modo muy exitoso, hasta tal punto que esta idea sigue siendo la base de los procesadores modernos actuales.
Hoy día en la creación de aplicaciones web, separamos por un lado el código y por otro los datos que van a circular a través de él. 
No obstante, considero interesante imaginar y plantear una aplicación web descrita de la misma forma en que se describen los datos.
De forma principalmente declarativa y usando tecnologías maduras como RDF como la base del modelo de datos.
El servidor web pasa a ser una base de datos, dónde las diferencias entre código y datos son puramente semánticas.

\section{Tripletas}

\section{Objetivos}

Los objetivos principales que se propusieron para Lyncex y que debían ser cumplidas son:

\begin{itemize}
    \item US1: Almacenar tripletas de datos junto a sus ontologías en el mismo espacio, validándose
    \item US2: Desarrollar una ontología que permita definir aplicaciones web sobre datos almacenados en el propio almacenamiento
    \item US3: Servir páginas web estáticas
    \item US4: Servir páginas web que necesiten leer datos del almacenamiento (plantillas)
    \item US5: Servir páginas web CRUD con formularios
\end{itemize}

Otros objetivos que estaría bien cumplir, pero no son necesarios para tener una versión funcional son:
\begin{itemize}
    \item OUS1: Servir páginas web con sistemas de autenticación y autorización propios
    \item OUS2: Servir APIs web de forma similar al contenido HTML
    \item OUS3: Tener un endpoint de consulta SPARQL
\end{itemize}

\chapter{Planificación}
Para el proyecto se ha tratado de seguir una metodología similar a SCRUM, obviando ciertas diferencias inherentes al trabajo invididual.
Primero se realizó una estimación, basada en puntos de historia, de cada una de las historias de usuario, pasando a formar parte del product backlog.
Estas historias de usuario representan los 5 objetivos mencionados anteriormente y existen ciertas dependencias entre ellas tal y como se puede ver en el gráfico.

MAPA DE DEPENDENCIAS

Merece especial mención la historia de usuario de desarrollo de ontología. Si bien podría ser un requisito previo de cara a otras historias de usuario, en la práctica
se han desarrollado de forma paralela, añadiendo lo necesario a la ontología en cada historia de usuario nueva.

Cada una de estas historias de usuario tenía asociadas diferentes condiciones de aceptación. Se trata de frases que siguen el estilo: Dado/Cuando/Entonces. 
Una implementación completa de la historia de usuario hará que todas las frases sean ciertas. Gracias a Behave, estas condiciones de aceptación no solo existen en el papel, sino en el código también que comprueba de forma activa además que no haya regresiones en etapas posteriores.

Estas historias de usuario a su vez se descompusieron en tareas lo más atómicas posibles, normalmente con una condición de aceptación asociada para saber que la tarea había acabado.

En metodología SCRUM, el trabajo se divide en sprints de varias semanas. En este caso en particular se eligieron sprints de tres semanas, aunque el tiempo real se decidía al inicio del sprint.
En esta reunión se elegían las tareas que debían a formar parte del sprint, formando parte de una lista conocida como sprint backlog.

En nuestra implementación particular de SCRUM, no había equipo, por tanto ciertos roles y ceremonias dejaban de tener interés. 
En este sentido, no se realizaron dailies y tanto el Product Owner como el equipo de desarrollo recayeron en mi persona, pudiendo asimilar el rol de Scrum Master al tutor del proyecto, Miguel Ángel Martínez Prieto.

\chapter{Estado del Arte}

Antes de adentrarnos en los detalles de Lyncex conviene recapitular ideas similares ya existentes así como herramientas que nos puedan ayudar. 

\section{Apache CouchDB}
Apache CouchDB es una base de datos NoSQL de tipo documental, almacenados estos en formato JSON.\cite{couchdb}
Su peculiaridad respecto a otras bases de datos similares como MongoDB viene por la forma de acceder a los datos.
Aunque en las últimas versiones CouchDB también dispone de un lenguaje de consulta, la forma original de acceder a la información era programando lo que se denominan vistas, en JavaScript.
Estas vistas generan un endpoint HTTP, que al ser llamado ejecutan el código JavaScript, en dos pasos. Primero un paso de map, para seleccionar los datos y realizar alguna transformación individual.
Posteriormente un paso de reduce permite realizar agregaciones. El código JavaScript que se ejecuta se almacena en la base de datos junto al resto de documentos.

Para interactuar con la base de datos se dispone de una API HTTP, tanto para crear como para borrar y o modificar los documentos.
Además dispone de un sistema de replicación entre nodos eventualmente consistente y relativamente simple, de forma que hay otros proyectos que implementan el mismo protocolo (PouchDB para navegadores web por ejemplo).

\section{TerminusDB}
TerminusDB es una base de datos programada en Prolog que comparte junto a CouchDB la característica de ser de tipo NoSQL de tipo documental.\cite{terminusdb}
Sin embargo, TerminusDB almacena tripletas RDF. RDF, como veremos más adelante, es un modelo de representación del conocimiento basado en tripletas.
TerminusDB cuenta con un lenguaje de consulta propio, admite ciertas validaciones sobre los datos y también dispone de una API HTTP.
TerminusDB no dispone de ninguna característica similar a las vistas de CouchDB.


\section{Django}
Django es uno de los frameworks web más populares dentro del mundo Python y es una referencia dentro del mundo de los frameworks web por su potencia y claridad de código.\cite{django}
Fuertemente inspirado por \textbf{Ruby on Rails}, adopta de él su filosofía DRY (Don't Repeat Yourself) y su \textit{convention over configuration}.
El framework trabaja con bases de datos relacionales principalmente, pero es una buena base para diseñar la semántica del servidor web.

Django sigue una arquitctura MTV, es decir, Model-Template-View. Es bastante similar al popular MVC, aunque según sus creadores, el controlador es el propio framework.
En Django el modelo se define como una clase de Python, que gracias al ORM, tiene persistencia en la base de datos. La parte de las plantillas se programa con un lenguaje similar a HTML, pero con capacidad de mostrar variables
y de cierta lógica (condicional, bucle) con metaetiquetas. La parte de vista es código Python puro. Existe un fichero especial llamado urls.py que contiene un listado que relaciona las URLs con las vistas.

Las vistas pueden acceder a los parámetros GET o POST directamente y operar sobre ellos así como a la sesión del usuario que visita la página.
Las vistas en Django pueden protegerse mediante un sistema de autenticación sencillo pero seguro, que permite bloquear fácilmente o redirigir si el usuario no ha iniciado sesión o si no tiene los permisos suficientes.
Estas características de Django tienen el denominador común de que son implementadas usando middleware, es decir, componentes del framework que se introducen entre la petición bruta original
y la vista.

Otra característica interesante de Django apoyada en el middleware es la gestión de formularios. Los formularios se definen en Django como una clase más, parecida a un modelo de base de datos (de hecho, se puede hacer que sea la misma clase).
Con esta clase Django puede generar parte de la plantilla automáticamente. Posteriormente, en el método POST, el middleware puede limpiar y validar los campos, de modo que a la vista llegan ya los datos limpios.

Por último, existe un componente llamado \textbf{Django REST Framework}, que añade funcionalidad para diseñar una API REST con los mismos patrones y facilidades que el desarrollo web HTML.

\section{Apache Jena}
Apache Jena es una base de datos de tripletas RDF, una de las más maduras si nos atenemos a su longevidad (Jena 1.0 es del año 2000).\cite{couchdb}
Implementa gran cantidad de estándares de la web semántica como RDF, RDF Schema, SPARQL, OWL, etc sin embargo no dispone tampoco de la capacidad de generar vistas web.

\section{Virtuoso y Marklogic}
OpenLink Virtuoso y MarkLogic son bases de datos multimodelo, entre ellos soportan el almacenamiento de tripletas.\cite{virtuoso}\cite{marklogic}.
Virtuoso tiene una versión opensource usada detrás de grandes silos de conocimiento como DBPedia o Wikidata. Ambas soportan queries vía SPARQL.

\section{ClioPatria}
ClioPatria es una aplicación que combina las librerías de RDF y HTTP de SWI-Prolog para ofrecer una base de datos semántica completa.\cite{cliopatria}
Soporta queries en SPARQL, SeRQL y en código Prolog. Al estar basada la aplicación en componentes independientes, podemos usarlos como base
de nuestra aplicación.

\section{Comparativa final}

Esta tabla representa como cumplen los objetivos propuestos en la sección Objetivos en cada uno de los programas analizados.


\begin{table}[ht]
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{llllllll}
                  & \textbf{CouchDB} & \textbf{TerminusDB} & \textbf{Django} & \textbf{Jena} & \textbf{Virtuoso} & \textbf{ClioPatria} & \textbf{Lyncex} \\
    \textbf{Almacén tripletas}  & No               & Sí                  & Sí (1)          & Sí            & Sí            & Sí                  & Sí              \\
    \textbf{Ontología disponible}  & No               & No                  & No              & No            & No                & No                  & Sí              \\
    \textbf{Webs estáticas}  & Sí               & No                  & Sí              & No            & No                & No                  & Sí              \\
    \textbf{Webs plantillas}  & Sí               & No                  & Sí              & No            & No                & No                  & Sí              \\
    \textbf{Webs CRUD}  & Sí               & No                  & Sí              & No            & No                & No                  & Sí              \\
    \textbf{Autenticación} & Sí               & No                  & Sí              & No            & No                & No                  & No              \\
    \textbf{APIs} & Sí               & No                  & Sí (2)          & No            & No                & No                  & No              \\
    \textbf{SPARQL} & No               & No                  & No              & Sí            & Sí                & Sí                  & No             
    \end{tabular}
    }
\end{table}

Notas:
\begin{enumerate}
    \item Aunque Django cuenta con un ORM muy potente para trabajar sobre el modelo relacional, nada impide usar otros modelos de almacenamiento.
    \item A través de Django REST Framework, un componente independiente pero altamente acoplado
\end{enumerate}

\chapter{Herramientas utilizadas}

A continuación se describen las herramientas utilizadas para Lyncex, tanto de desarrollo como librerías y entornos que necesita en tiempo de ejecución.
\section{SWI Prolog}
SWI Prolog\cite{prolog} es un entorno de programación Prolog, ampliamente usado gracias a su condición de software libre, su portabilidad y 
su estrategia de baterías incluidas, que hace que disponga de gran cantidad de librerías y módulos por defecto.
La comunidad de SWI Prolog es pequeña pero activa y a parte de la gran cantidad de librerías, existe un sistema de packs, que permiten instalar librerías de terceros.

Entre los módulos que tiene SWI Prolog y que es difícil encontrar en otras implementaciones, debemos destacar los módulos de web semántica y RDF y los de HTTP.
Sin estos módulos, la realización de Lyncex hubiese sido mucho más compleja y alargada en el tiempo.

\section{RDF, Turtle}
RDF, siglas de Resource Description Framework, es un modelo de datos para describir datos usando tripletas sujeto-predicado-objeto. 
Se trata de un estándar del W3C y dispone de una variedad de sintaxis. Se ha elegido Turtle como sintaxis predeterminada ya que es la que en nuestra opinión es la más simple y menos verbosa.
Otros formatos alternativos como RDF/XML o JSON-LD parten de formatos diseñados para ser usados de forma diferente, añadiendo complejidad y verbosidad en el camino.

\section{IDE}
Como IDE se ha utilizado Visual Studio Code\cite{vscode}, un editor propiedad de Microsoft, pero multiplataforma.
Es un IDE con el que ya había familaridad previa y no supone ningún esfuerzo usarlo para este proyecto.
Visual Studio Code dispone de un sistema de plugins, y entre otros, hay plugins de Prolog y de Turtle.
El último fue usado para obtener resaltado de sintaxis, mientras que el primero se evaluó y finalmente se deshechó.
El motivo es que el plugin ejecuta Prolog por debajo para detectar errores de sintaxis, pero al tratarse de una aplicación que es un servidor, al ejecutarse toma los puertos y no podemos usarlos
en pruebas lanzadas a través de la terminal.

\section{Sistema operativo}
La totalidad del proyecto se ha realizado sobre Debian, en su versión Sid. Se trata de un sistema operativo con kernel Linux, 
de amplio uso en servidores, y también usado, en menor medida, en portátiles y workstations.

\section{Docker}
Para que los entornos de prueba y de ejecución sean reproducibles, se ha optado por usar Docker y su utilidad, Docker Compose.
Docker es un sistema de contenedores para Linux que proporciona capacidades de aislamiento y reproducibilidad de entornos similares a las máquinas virtuales, sin el overhead que usar estas conlleva.
Existen otros sistemas parecidos, como LXD, pero Docker tiene varias ventajas: poder describir entornos como código versionable (Dockerfile) y poder orquestar de forma sencilla entornos pequeños y medianos (docker-compose).

\section{Git y GitHub}
Para versionar el código fuente se ha usado el sistema Git, usando como almacenamiento GitHub. Principalmente se ha usado a través de la línea de comandos.
No se han aprovechado muchas de sus características de ramas y merges, ya que al ser un proyecto personal, solo se iba modificando una parte del programa a la vez.
Adicionalmente se ha hecho uso de la integración continua gratuita ofrecida por GitHub llamada GitHub Actions. De este modo se ha definido una acción que se ejecuta al recibir nuevo código en el repositorio.
Esta acción construía las imágenes de Docker necesarias y pasaba los tests de Behave y de PlUnit.

\section{Behave}
Para asegurarnos que las historias de usuario se implementaban correctamente se ha decidido usar Behave.
Se trata de un framework para definir tests en lenguaje Gherkin, un lenguaje muy similar al lenguaje natural. Estos tests se componen de pasos,
los cuáles son implementados en Python. Como las historias de usuario nos hablan de como debe reaccionar el sistema con el exterior, no hay problema en implementar los tests de este tipo en otro lenguaje.

\chapter{Análisis del sistema}

\chapter{Diseño de la ontología}

\chapter{Componentes del sistema}
Lyncex es una aplicación Prolog que se ejecuta a modo de servidor. Se recomienda utilizar la aplicación desde un contenedor Docker, si bien no es estrictamente necesario. 
Una vez lanzado, la única forma de interactuar con el sistema es mediante la API.

\section{API}
La API de Lyncex se encarga de que el sistema interactúe con el exterior.
Un programador que desee crear una aplicación de Lyncex es lo único que debería tocar.
Externamente se trata de una API HTTP, que define varias rutas bajo la ruta \_api.
Las operaciones que soporta la API son:
\begin{itemize}
    \item Creación de tripletas en la base de datos (POST, \_api)
    \item Borrado de tripletas de la base de datos (DELETE, \_api/delete) con posibilidad de aplicar filtros
    \item Lectura de tripletas de la base de datos (GET, \_api/query) con posibilidad de aplicar filtros
\end{itemize}

La creación de tripletas toma como entrada un fichero de tipo Turtle, mismo formato que se encuentra a la salida de la lectura de tripletas.
De esta forma, se pueden realizar backups rápidos de la aplicación.

El componente API además dispone de una validación elemental de RDF Schema.
Esto se consigue si tanto los datos como las ontologías que los definen coexisten en la aplicación.
Se verifica básicamente el uso correcto de instancias y propiedades mediante rdfs:domain.
Técnicamente, RDF Schema no es un lenguaje de validación al uso, sino más bien de descripción de datos, pero demasiado abierto como para hacer comprobaciones estrictas.
Es por ello que solo se valida este único comportamiento.


\section{Controladores}
Los controladores son los componentes que implementan la funcionalidad principal definida por la ontología.
Al llegar una petición, se van probando los diferentes tipos de controladores hasta encontrar uno que sea del tipo al definido en la tripleta: (Controlador, rdf:type, lyncex:TipoControlador).
Inicialmente se han diseñado tres controladores.

\subsection{ContentController}
El más básico de todos, simplemente devuelve lo que tenga definido en la tripleta (Controlador, lyncex:content, Content) con el tipo MIME 
de la tripleta (Controlador, lyncex:mime, MimeType). El nodo Content es del tipo ContentAsText o ContentAsBase64, permitiendo ambos modos de representación del contenido.
Ambos tipos forman parte de la ontología de W3C llamada \textit{Representing Content in RDF 1.0}\cite{cnt}.
El tipo ContentAsText está pensado para formatos de tipo texto (HTML, CSS, JavaScript) mientras que ContentAsBase64 está pensado para formatos binarios (imágenes, sonidos, etc).
Hay que mencionar, que en ningún caso almacenar ficheros binarios codificados en base 64 es una opción óptima y esta opción se ofrece más como una conveniencia.

\subsection{TemplateController}
El TemplateController se encarga de gestionar las plantillas. Estas plantillas se definen siguiendo la sintaxis Semblance de la librería simple-template.
El TemplateController realiza las siguientes operaciones en orden:
\begin{enumerate}
    \item Procesado de parámetros GET y POST definidos previamente por instancias lyncex:Parameter
    \item Templatizado de queries (si lo hubiera) especificadas (instancias de lyncex:Query)
    \item Resolución de las queries (si hubiera)
    \item Ejecución de los handlers (si hubiera) (instancias de lyncex:Handler)
    \item Templatizado final
\end{enumerate}

\subsection{FormController}
El FormController es una abstracción por encima del TemplateController a nivel interno, pero de cara a la ontología no es una subclase.
Su funcionamiento depende de si se realiza una petición POST o GET. Ante una petición POST, el controlador procesará los parámetros.
Buscará la existencia de un parámetro llamado \_id en primer lugar, ya que definirá el sujeto sobre el que se van a almacenar tripletas.
A continuación recorrerá el resto de parámetros. El nombre de cada parámetro es la URL de la propiedad y el valor será el valor de la propiedad.
Actualmente no se soporta crear dos tripletas de la misma propiedad en el mismo procesado.

Si tenemos una operación GET, el controlador leerá la clase base y todas las propiedades que pueda extraer de la clase. Para ello es importante que la ontología de los datos esté cargada, si no, no será capaz de adivinar qué propiedades admite la clase.
Una vez tenga el listado de propiedades, generará un formulario HTML ajustando todos los valores de forma adecuada al formato de aceptación del POST.

\section{Procesado de parámetros}
El procesado de parámetros es llamado por diferentes controladores para adaptar el formato de entrada HTTP GET y POST a un formato común (un diccionario Prolog).
Solo saldrán del procesado aquellos parámetros indicados de forma explícita, ignorando aquellos que no lo estén.
Durante el procesado se ejecutan las validaciones si las hubiera. Existen dos tipos de validaciones: Regex y Prolog.
Cualquier parámetro puede tener cero, una o ambas validaciones.

La validación regex, simplemente comprueba que el valor del parámetro cumpla con el patrón de una expresión regular estándar. Por debajo se implementa mediante la librería PCRE.

La validación Prolog es código Prolog que define un término validation(X). Dentro de este código se puede llamar a cualquier código Prolog.
La validación será exitosa si el término se puede evaluar a true, en caso contrario, se considerará que el parámetro está mal y fallará.

\section{Enrutado}

\chapter{Validación y pruebas}

\section{Pruebas manuales}

\section{Tests unitarios}

\section{Test E2E}

\chapter{Manuales}

\chapter{Conclusiones}

\chapter{Trabajo futuro}

\bibliographystyle{acm}

\bibliography{ref}

\end{document}